{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27adb7d3",
   "metadata": {},
   "source": [
    "Import stock listing info from the NASDAQ\n",
    "In this video, you learned how to use the pd.read_csv() function to import data from a csv file containing companies listed on the AmEx Stock Exchange into a pandas DataFrame. You can apply this same knowledge to import listing information in csv files from other stock exchanges.\n",
    "\n",
    "The next step is to ensure that the contents of the DataFrame accurately reflect the meaning of your data. Two essential methods to understand your data are .head(), which displays the first five rows of your data by default, and .info(), which summarizes elements of a DataFrame such as content, data types, and missing values.\n",
    "\n",
    "In this exercise, you will read the file nasdaq-listings.csv with data on companies listed on the NASDAQ and then diagnose issues with the imported data. You will fix these issues in the next exercise.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Load pandas as pd.\n",
    "Use pd.read_csv() to load the file nasdaq-listings.csv into the variable nasdaq.\n",
    "Use .head() to display the first 10 rows of the data. Which data type would you expect pandas to assign to each column? What symbol is used to represent a missing value?\n",
    "Use .info() to identify dtype mismatches in the DataFrame summary. Specifically, are there any columns that should have a more appropriate type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Import the data\n",
    "nasdaq = pd.read_csv('nasdaq-listings.csv')\n",
    "\n",
    "# Display first 10 rows\n",
    "print(nasdaq.head(10))\n",
    "\n",
    "# Inspect nasdaq\n",
    "nasdaq.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c465eb",
   "metadata": {},
   "source": [
    "Read data using .read_csv() with adequate parsing arguments\n",
    "You have successfully identified the issues you must address when importing the given csv file.\n",
    "\n",
    "In this exercise, you will once again load the NASDAQ data into a pandas DataFrame, but with a more robust function. pandas has been imported as pd.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Read the file nasdaq-listings.csv into nasdaq with pd.read_csv(), adding the arguments na_values and parse_dates equal to the appropriate values. You should use 'NAN' for missing values, and parse dates in the Last Update column.\n",
    "Display and inspect the result using .head() and .info() to verify that the data has been imported correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ff1188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "nasdaq = pd.read_csv('nasdaq-listings.csv', na_values='NAN', parse_dates=['Last Update'])\n",
    "\n",
    "# Display the head of the data\n",
    "print(nasdaq.head())\n",
    "\n",
    "# Inspect the data\n",
    "nasdaq.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13773dfc",
   "metadata": {},
   "source": [
    "Load listing info from a single sheet\n",
    "As you just learned, you can import data from a sheet of an Excel file with the pd.read_excel() function by assigning the optional sheet_name argument to an integer indicating its position or a string containing its name.\n",
    "\n",
    "pandas.read_excel(file, sheetname=0, na_values=None, ...)\n",
    "Here, you will practice by importing NYSE data from a new file, listings.xlsx. pandas has been imported as pd.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Read only the 'nyse' worksheet of 'listings.xlsx' where the symbol 'n/a' represents missing values. Assign the result to nyse.\n",
    "Display and inspect nyse with .head() and .info()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551d257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "nyse = pd.read_excel('listings.xlsx', na_values = 'n/a', sheetname='nyse')\n",
    "\n",
    "# Display the head of the data\n",
    "print(nyse.head())\n",
    "\n",
    "# Inspect the data\n",
    "nyse.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993bf658",
   "metadata": {},
   "source": [
    "Load listing data from two sheets\n",
    "The import process is just as intuitive when using the sheet_names attribute of a pd.ExcelFile() object.\n",
    "\n",
    "Passing in a list as the sheetname argument of pd.read_excel(), whether you assign the list to a variable holding the sheet_names attribute of a pd.ExcelFile() object or type the list out yourself, constructs a dictionary. In this dictionary, the keys are the names of the sheets, and the values are the DataFrames containing the data from the corresponding sheet. You can extract values from a dictionary by providing a particular key in brackets.\n",
    "\n",
    "In this exercise, you will retrieve the list of stock exchanges from listings.xlsx and then use this list to read the data for all three exchanges into a dictionary. pandas has been imported as pd.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Create a pd.ExcelFile() object using the file 'listings.xlsx' and assign to xls.\n",
    "Save the sheet_names attribute of xls as exchanges.\n",
    "Using exchanges to specify sheet names and n/a to specify missing values in pd.read_excel(), read the data from all sheets in xls, and assign to a dictionary listings.\n",
    "Inspect only the 'nasdaq' data in this new dictionary with .info()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c78d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pd.ExcelFile() object\n",
    "xls = pd.ExcelFile('listings.xlsx')\n",
    "\n",
    "# Extract sheet names and store in exchanges\n",
    "exchanges = xls.sheet_names\n",
    "\n",
    "# Create listings dictionary with all sheet data\n",
    "listings = pd.read_excel(xls, sheet_name = exchanges, na_values='n/a')\n",
    "\n",
    "# Inspect NASDAQ listings\n",
    "listings['nasdaq'].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba2903d",
   "metadata": {},
   "source": [
    "Load all listing data and iterate over key-value dictionary pairs\n",
    "You already know that a pd.DataFrame() object is a two-dimensional labeled data structure. As you saw in the video, the pd.concat() function is used to concatenate, or vertically combine, two or more DataFrames. You can also use broadcasting to add new columns to DataFrames.\n",
    "\n",
    "In this exercise, you will practice using this new pandas function with the data from the NYSE and NASDAQ exchanges. pandas has been imported as pd.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Import data in listings.xlsx from sheets 'nyse' and 'nasdaq' into the variables nyse and nasdaq, respectively. Read 'n/a' to represent missing values.\n",
    "Inspect the contents of both DataFrames with .info() to find out how many companies are reported.\n",
    "With broadcasting, create a new reference column called 'Exchange' holding the values 'NYSE' or 'NASDAQ' for each DataFrame.\n",
    "Use pd.concat() to concatenate the nyse and nasdaq DataFrames, in that order, and assign to combined_listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca2d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the NYSE and NASDAQ listings\n",
    "nyse = pd.read_excel('listings.xlsx', sheet_name='nyse', na_values='n/a')\n",
    "nasdaq = pd.read_excel('listings.xlsx', sheet_name='nasdaq', na_values='n/a')\n",
    "\n",
    "# Inspect nyse and nasdaq\n",
    "nyse.info()\n",
    "nasdaq.info()\n",
    "\n",
    "# Add Exchange reference columns\n",
    "nyse['Exchange'] = 'NYSE'\n",
    "nasdaq['Exchange'] = 'NASDAQ'\n",
    "\n",
    "# Concatenate DataFrames  \n",
    "combined_listings = pd.concat([nyse, nasdaq])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ea552b",
   "metadata": {},
   "source": [
    "Automate the loading and combining of data from multiple Excel worksheets\n",
    "You are now ready to automate the import process of listing information from all three exchanges in the Excel file listings.xlsx by implementing a for loop. Let's look at what you'll do:\n",
    "\n",
    "Retrieve the sheet names of a pd.ExcelFile() object using its sheet_names attribute.\n",
    "Create an empty list.\n",
    "Write a for loop that iterates through these sheet names to read the data from the corresponding sheet name in the Excel file into a variable. Add a reference column, if desired. Append the contents of this variable to the list with each iteration.\n",
    "Concatenate the DataFrames in the list.\n",
    "As always, refer to the previous exercises in this chapter or the pandas documentation if you need any help. pandas has been imported as pd.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Create the pd.ExcelFile() object using the file listings.xlsx and assign to the variable xls.\n",
    "Retrieve the sheet names from the .sheet_names attribute of xls and assign to exchanges.\n",
    "Create an empty list and assign to the variable listings.\n",
    "Iterate over exchanges using a for loop with exchange as iterator variable. In each iteration:\n",
    "Use pd.read_excel() with xls as the the data source, exchange as the sheetname argument, and 'n/a' as na_values to address missing values. Assign the result to listing.\n",
    "Create a new column in listing called 'Exchange' with the value exchange (the iterator variable).\n",
    "Append the resulting listing DataFrame to listings.\n",
    "Use pd.concat() to concatenate the contents of listings and assign to listing_data.\n",
    "Inspect the contents of listing_data using .info()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c477f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pd.ExcelFile() object\n",
    "xls = pd.ExcelFile('listings.xlsx')\n",
    "\n",
    "# Extract the sheet names from xls\n",
    "exchanges = xls.sheet_names\n",
    "\n",
    "# Create an empty list: listings\n",
    "listings = []\n",
    "\n",
    "# Import the data\n",
    "for exchange in exchanges:\n",
    "    listing = pd.read_excel(xls, sheetname=exchange, na_values='n/a')\n",
    "    listing['Exchange'] = exchange\n",
    "    listings.append(listing)\n",
    "\n",
    "# Concatenate the listings: listing_data\n",
    "listing_data = pd.concat(listings)\n",
    "\n",
    "# Inspect the results\n",
    "listing_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3b3759",
   "metadata": {},
   "source": [
    "Get stock data for a single company\n",
    "Google Finance has deprecated their API but DataReader now makes available the data source 'iex'. To experiment with the data outside DataCamp environment, you will need an IEX Cloud account.\n",
    "\n",
    "The most important change to the functionality is the limitation of the data to the last five years.\n",
    "\n",
    "Retrieving stock price data from IEX is simple after importing the DataReader package and using the start and/or end arguments in form date(YYYY, MM, DD):\n",
    "\n",
    "stock_data = DataReader(ticker, data_source, start, end)\n",
    "In the first chapter, you learned that a stock ticker is the unique symbol needed to get stock information for a certain company.\n",
    "\n",
    "In this exercise, you will practice importing the 2016 data for Apple, with ticker 'AAPL'.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Import the DataReader from pandas_datareader.data and date from the datetime library.\n",
    "Using date(), set the start date to January 1, 2016 and end date to December 31, 2016.\n",
    "Set ticker to Apple's stock ticker 'AAPL' and data_source to 'iex'.\n",
    "Create a DataReader() object to import the stock prices and assign to a variable stock_prices.\n",
    "Use .head() and .info() to display and inspect the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02145d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DataReader\n",
    "from pandas_datareader.data import DataReader\n",
    "\n",
    "# Import date\n",
    "from datetime import date\n",
    "\n",
    "# Set start and end dates\n",
    "start = date(2016,1,1)\n",
    "end = date(2016,12,31)\n",
    "\n",
    "# Set the ticker\n",
    "ticker = 'AAPL'\n",
    "\n",
    "# Set the data source\n",
    "data_source = 'iex'\n",
    "\n",
    "# Import the stock prices\n",
    "stock_prices = DataReader(ticker, data_source, start, end)\n",
    "\n",
    "# Display and inspect the result\n",
    "print(stock_prices.head())\n",
    "stock_prices.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f233e8",
   "metadata": {},
   "source": [
    "Visualize a stock price trend\n",
    "Google Finance has deprecated their API but DataReader now makes available the data source 'iex'. To experiment with the data outside DataCamp environment, you will need an IEX Cloud account.\n",
    "\n",
    "The most important change to the functionality is the limitation of the data to the last five years. The DataFrame returned by the DataReader has the same columns, but in lower case.\n",
    "\n",
    "The matplotlib.pyplot package is essential to visualizing stock price trends in Python.\n",
    "\n",
    "In this exercise, you will import 2016 stock price data for Facebook, and then plot its closing price for the entire period! DataReader and date have already been imported.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Import matplotlib.pyplot as plt.\n",
    "Using date(), set the start and end dates to January 1, 2016 and December 31, 2016, respectively.\n",
    "Set ticker to Facebook's stock ticker 'FB' and data_source to 'iex'.\n",
    "Create a DataReader() object to import the stock prices and assign to stock_prices.\n",
    "Plot the 'close' data in stock_prices, set ticker as the title, and show the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3a961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set start and end dates\n",
    "start = date(2016, 1, 1)\n",
    "end = date(2016, 12, 31)\n",
    "\n",
    "# Set the ticker and data_source\n",
    "ticker = 'FB'\n",
    "data_source = 'iex'\n",
    "\n",
    "# Import the data using DataReader\n",
    "stock_prices = DataReader(ticker, data_source, start, end)\n",
    "\n",
    "# Plot close\n",
    "stock_prices['close'].plot(title=ticker)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee8807b",
   "metadata": {},
   "source": [
    "Visualize the long-term oil price trend\n",
    "In the previous video, you learned how to retrieve data from the Federal Reserve Economic Data (FRED) portal.\n",
    "\n",
    "Here, you will use this new data source to visualize the oil price trend over the last 50 years, specifically, the Spot Crude Oil Price: West Texas Intermediate (WTI). DataReader, date, pandas as pd, and matplotlib.pyplot as plt have been imported.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Use date() to set start to January 1, 1968, and set series to series code 'WTISPLC'.\n",
    "Pass series as the data,'fred' as the data source, and start as the start date to DataReader(). Assign to oil_price.\n",
    "Inspect oil_price using .info().\n",
    "Plot and show the oil_price series with title 'Oil Price'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b403666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set start date\n",
    "start = date(1968, 1, 1)\n",
    "\n",
    "# Set series code\n",
    "series = 'WTISPLC'\n",
    "\n",
    "# Import the data\n",
    "oil_price = DataReader(series, 'fred', start)\n",
    "\n",
    "# Inspect the price of oil\n",
    "oil_price.info()\n",
    "\n",
    "# Plot the price of oil\n",
    "oil_price['WTISPLC'].plot(title = 'Oil Price')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ffae84",
   "metadata": {},
   "source": [
    "Compare labor market participation and unemployment rates\n",
    "Two economic data series in FRED are the Civilian Unemployment Rate ('UNRATE') and the Civilian Labor Force Participation Rate ('CIVPART').\n",
    "\n",
    "These rates highlight two important aspects of the US labor market: the share of the civilian population that is currently unemployed or seeking employment, and the share of those active in the labor market that are in fact employed.\n",
    "\n",
    "This means that the numbers indicate both the size of the labor market relative to the total population, as well as the size of unemployment relative to the labor market.\n",
    "\n",
    "Here, you will import, modify, and plot the data. DataReader, date, pandas as pd, and matplotlib.pyplot as plt have been imported.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Using date(), set start to January 1, 1950.\n",
    "Create series as a list containing the series codes 'UNRATE' and 'CIVPART', in that order.\n",
    "Pass series, the data source 'fred', and the start date to DataReader(), and assign the result to econ_data.\n",
    "Use the .columns attribute to assign 'Unemployment Rate' and 'Participation Rate' as the new column labels.\n",
    "Plot and show econ_data using the subplots=True argument, and title it 'Labor Market'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dbd4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the start date\n",
    "start = date(1950,1,1)\n",
    "\n",
    "# Define the series codes\n",
    "series = ['UNRATE', 'CIVPART']\n",
    "\n",
    "# Import the data\n",
    "econ_data = DataReader(series, 'fred', start)\n",
    "\n",
    "# Assign new column labels\n",
    "econ_data.columns = ['Unemployment Rate', 'Participation Rate']\n",
    "\n",
    "# Plot econ_data\n",
    "econ_data.plot(subplots = True, title = 'Labor Market')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f87808",
   "metadata": {},
   "source": [
    "Compare bond and stock performance\n",
    "Bonds and stocks are the most important investment alternatives. Now that you can import data from both the Federal Reserve and Google Finance, you can compare the performance of both asset classes. You'll be using a Total Return Index for each class, which accounts for returns due to both price increases and payments like interest or dividends.\n",
    "\n",
    "For bonds, you'll use the Bank of America Merrill Lynch US High Yield Total Return Index Value ('BAMLHYH0A0HYM2TRIV'). For stocks, you'll use the S&P 500 Index ('SP500'). Both are available for the past 10 years from the Federal Reserve's FRED service.\n",
    "\n",
    "In this exercise, you will download both series and compare their performance. DataReader, date, pandas as pd, and matplotlib.pyplot as plt have been imported.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Using date(), set the start date to January 1, 2008.\n",
    "Set the series codes as a list containing 'BAMLHYH0A0HYM2TRIV' and 'SP500'.\n",
    "Use DataReader() to import both series from 'fred' and assign to data.\n",
    "Plot and show data with subplots, titled 'Performance Comparison'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fa985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the start date\n",
    "start = date(2008, 1, 1)\n",
    "\n",
    "# Set the series codes\n",
    "series = ['BAMLHYH0A0HYM2TRIV', 'SP500']\n",
    "\n",
    "# Import the data\n",
    "data = DataReader(series, 'fred', start)\n",
    "\n",
    "# Plot the results\n",
    "data.plot(subplots = True, title = 'Performance Comparison')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39c99b6",
   "metadata": {},
   "source": [
    "Select the top 5 listed consumer companies\n",
    "As you have just learned, it is possible to filter stocks based on criteria with the sort_values() method and an argument that specifies the column to filter by. Additionally, you can include the argument ascending=False to sort entries from highest to lowest.\n",
    "\n",
    "Here, you will use this function to find out the five most valuable companies in the Consumer Services sector. This is measured with market capitalization, or the combined value of all shares in a company. pandas has been imported as pd, as has the listings DataFrame from the first chapter. As a refresher, it contains data from the AMEX, NYSE, and NASDAQ.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Without using .loc[], filter listings based on the condition that the 'Sector' is equal to 'Consumer Services' and assign to consumer_services.\n",
    "Sort consumer_services by 'Market Capitalization' in descending order and assign it to consumer_services2.\n",
    "Using .head(), display the first 5 rows of the 'Company Name', 'Exchange', and 'Market Capitalization' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747dea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select companies in Consumer Services\n",
    "consumer_services = listings[listings.Sector == 'Consumer Services']\n",
    "\n",
    "# Sort consumer_services by market cap\n",
    "consumer_services2 = consumer_services.sort_values('Market Capitalization', ascending=False)\n",
    "\n",
    "# Display first 5 rows of designated columns\n",
    "print(consumer_services2[['Company Name', 'Exchange', 'Market Capitalization']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf68dc",
   "metadata": {},
   "source": [
    "Get the ticker of the largest consumer services company\n",
    "Google Finance has deprecated their API but DataReader now makes available the data source 'iex' that provides the same functionality. To experiment with the data outside DataCamp environment, you will need an IEX Cloud account.\n",
    "\n",
    "Instead of indexing your data with a conditional expression, you can also filter by certain values with .loc[row_selector, column_selector]. Additionally, you can use .set_index() to set a particular column with unique values as the index of a DataFrame, and .idxmax() to return the index of the maximum value.\n",
    "\n",
    "In this exercise, you will apply these methods of selecting companies to find the most valuable consumer services company on any of the three exchanges, and use its ticker to plot its stock price trend. DataReader, date, pandas as pd, and matplotlib.pyplot as plt have been imported, as has the listings DataFrame from the last exercise.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Use .set_index() to set the 'Stock Symbol' column as the index for listings, assigning it to listings_ss.\n",
    "Use .loc[] to filter rows where 'Sector' is equal to 'Consumer Services', select the column 'Market Capitalization', and apply .idxmax() to assign the ticker of the largest Consumer Services company to ticker.\n",
    "Using date(), set start to January 1, 2015.\n",
    "Use DataReader() to extract the stock data for the ticker from 'iex' since start and store in data.\n",
    "Plot the 'close' and 'volume' values in data, with arguments secondary_y='volume' and title=ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe3c358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index of listings to Stock Symbol\n",
    "listings_ss = listings.set_index('Stock Symbol')\n",
    "\n",
    "# Get ticker of the largest Consumer Services company\n",
    "ticker = listings_ss.loc[listings_ss.Sector == 'Consumer Services', 'Market Capitalization'].idxmax()\n",
    "\n",
    "# Set the start date\n",
    "start = date(2015, 1, 1)\n",
    "\n",
    "# Import the stock data\n",
    "data = DataReader(ticker, 'iex', start)\n",
    "\n",
    "# Plot close and volume\n",
    "data[['close', 'volume']].plot(secondary_y='volume', title=ticker)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae6e12b",
   "metadata": {},
   "source": [
    "Get the largest consumer company listed after 1998\n",
    "Google Finance has deprecated their API but DataReader now makes available instead the data source 'iex'. To experiment with the data outside DataCamp environment, you will need an IEX Cloud account.\n",
    "\n",
    "The functionality using 'iex' is the same except: data is limited to the last five years, column headers are lower case.\n",
    "\n",
    "You can filter your data by even more conditions by enclosing each condition in parentheses and using logical operators like & and |.\n",
    "\n",
    "Here, you will find out which company is the largest consumer services company that went public after Amazon did in 1997. The data is contained in the column 'IPO Year'; an Initial Public Offering (IPO) is a financial term that describes the first time that the stock of a private company is offered to the public.\n",
    "\n",
    "DataReader, date, pandas as pd, and matplotlib.pyplot as plt have been imported. The listings DataFrame from the last exercise is also available.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Set 'Stock Symbol' as the index for listings.\n",
    "Use .loc[] to filter rows where 'Sector' is 'Consumer Services' and IPO Year starting 1998, and also select the 'Market Capitalization' column. Apply .idxmax() and assign the result to ticker.\n",
    "Set the start date to January 1, 2015.\n",
    "Use the DataReader to get the stock data for the ticker from 'iex' since start.\n",
    "Plot the 'close' and 'volume' prices of this company, using 'volume' for secondary_y and ticker as the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ffbfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Stock Symbol as the index\n",
    "listings = listings.set_index('Stock Symbol')\n",
    "\n",
    "# Get ticker of the largest consumer services company listed after 1997\n",
    "ticker = listings.loc[(listings.Sector == 'Consumer Services') & (listings['IPO Year'] > 1998), 'Market Capitalization'].idxmax()\n",
    "\n",
    "# Set the start date\n",
    "start = date(2015, 1, 1)\n",
    "\n",
    "# Import the stock data\n",
    "data = DataReader(ticker, 'iex', start)\n",
    "\n",
    "# Plot close and volume\n",
    "data[['close', 'volume']].plot(secondary_y = 'volume', title = ticker)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c10c4d",
   "metadata": {},
   "source": [
    "Get data for the 3 largest financial companies\n",
    "Google Finance has deprecated their API but DataReader now makes available instead the data source 'iex'. To experiment with the data outside DataCamp environment, you will need an IEX Cloud account.\n",
    "\n",
    "The functionality using 'iex' is the same except: data is limited to the last five years, column headers are lower case, and for multiple tickers the return value is a dictionary rather than a pandas.Panel. We have included a few lines of code in the exercise to convert the dictionary into a DataFrame with MultiIndex like in the video.\n",
    "\n",
    "A pd.MultiIndex() object has more than one identifier per row. This allows you to get the data based on criteria for multiple companies at once.\n",
    "\n",
    "Let's apply this new skill to get the stock prices for the largest companies in the financial sector. DataReader, date, pandas as pd, and matplotlib.pyplot as plt have been imported, as has the listings DataFrame from the last exercise.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Set 'Stock Symbol' as the index for listings, assigning it to listings_ss.\n",
    "Use .loc[] to filter rows where the company sector is 'Finance'and extract the 'Market Capitalization' column. Apply .nlargest() to assign the 3 largest companies by market cap to top_3_companies.\n",
    "Convert the index of the result to a list and assign it to top_3_tickers.\n",
    "Use date() to set start to January 1, 2015.\n",
    "Use date() to set end to April 1, 2020.\n",
    "Use the DataReader() to get the stock data for the top_3_tickers from 'iex' since start until end and assign it to result.\n",
    "We are then creating a DataFrame by iterating over the ticker-data pairs and create a MultiIndex by appending 'ticker' to 'date' in the Index.\n",
    "Select 'close' from data, apply .unstack(), and inspect the resulting DataFrame, now in wide format, with .info()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4935c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Stock Symbol as the index\n",
    "listings_ss = listings.set_index('Stock Symbol')\n",
    "\n",
    "# Get ticker of 3 largest finance companies\n",
    "top_3_companies = listings_ss.loc[listings_ss.Sector == 'Finance', 'Market Capitalization'].nlargest(n=3)\n",
    "\n",
    "# Convert index to list\n",
    "top_3_tickers = top_3_companies.index.tolist()\n",
    "\n",
    "# Set start date\n",
    "start = date(2015, 1, 1)\n",
    "\n",
    "# Set end date\n",
    "end = date(2020, 4, 1)\n",
    "\n",
    "# Import stock data\n",
    "result = DataReader(top_3_tickers, 'iex', start, end)\n",
    "result = result[~result.index.duplicated()]\n",
    "data = pd.DataFrame()\n",
    "for ticker in result.columns.levels[1]:\n",
    "    index = pd.MultiIndex.from_arrays([\n",
    "            [ticker] * len(result),\n",
    "            result.index.values\n",
    "            ], names=['ticker', 'date'])\n",
    "    ticker_df = pd.DataFrame(index=index)\n",
    "    for col in result.columns.levels[0]:\n",
    "        ticker_df[col] = result[col][ticker].values\n",
    "    data = pd.concat([data, ticker_df])\n",
    "\n",
    "# Unstack and inspect result\n",
    "data['close'].unstack().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272d82fc",
   "metadata": {},
   "source": [
    "List the poorest and richest countries worldwide\n",
    "The values of numerical variables are numbers. They can be described by measures of central tendency, or the most typical value in a dataset, and dispersion, which represents the spread of a distribution.\n",
    "\n",
    "In the next few exercises, you will use these statistics to explore the data in 'per_capita_income.csv', which contains the average income earned per person in a given country. The first step in analyzing aspects of the global income distribution is to inspect and familiarize yourself with the data.\n",
    "\n",
    "pandas has been imported as pd.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Load the 'per_capita_income.csv' file into income. No additional arguments other than the file name are needed. (Note that this is a csv file.)\n",
    "Inspect the column names and data types with .info().\n",
    "Using .sort_values(), sort (in descending order) the income DataFrame by the column which contains the income information.\n",
    "Display the first five rows of income using .head() and the last five rows using .tail()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3632d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "income = pd.read_csv('per_capita_income.csv')\n",
    "\n",
    "# Inspect the result\n",
    "income.info()\n",
    "\n",
    "# Sort the data by income\n",
    "income = income.sort_values('Income per Capita', ascending = False)\n",
    "\n",
    "# Display the first and last five rows\n",
    "print(income.head())\n",
    "print(income.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ab425c",
   "metadata": {},
   "source": [
    "Global incomes: Central tendency\n",
    "The most common measures of central tendency are the mean, which is equal to the sum of all values divided by the total number of values, median, which separates the upper half of data from the lower half, and mode, which is the most frequent value in the data set. The pandas package contains functions that can calculate each of these.\n",
    "\n",
    "In this data set, the values for 'Income per Capita' are floats, and there are no repeat values, so running income['Income per Capita'].mode() in your console returns an empty series. Here, you will use the floor division operator // to add a new column that measures income in thousands, rounded down, so that a value such as 11,543.43 becomes just 11. Then, you will run the above functions to better understand how incomes are distributed.\n",
    "\n",
    "pandas has been imported as pd, and the income DataFrame from the previous exercise is in your workspace.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Use the appropriate function to calculate the global mean of 'Income per Capita'.\n",
    "Use the appropriate function to calculate the global median of 'Income per Capita'.\n",
    "Using broadcasting, create a new column 'Income per Capita (,000)' equal to income['Income per Capita'] // 1000. Then use the appropriate function to calculate the mode for this new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a075f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean\n",
    "print(income['Income per Capita'].mean())\n",
    "\n",
    "# Calculate the median\n",
    "print(income['Income per Capita'].median())\n",
    "\n",
    "# Create the new column\n",
    "income['Income per Capita (,000)'] = income['Income per Capita']//1000\n",
    "\n",
    "# Calculate the mode of the new column\n",
    "income['Income per Capita (,000)'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bf5bb9",
   "metadata": {},
   "source": [
    "Global incomes: Dispersion\n",
    "A quantile is a measure of dispersion created by dividing a frequency distribution of a DataFrame into even groups. You can return values at the given quantile q of a DataFrame df with the command df.quantile(q); likewise, supplying a list as q will return a value for each given quantile.\n",
    "\n",
    "Here, you will continue your analysis of global income distribution using two measures of dispersion: the standard deviation, or square root of variance, and the interquartile range (IQR).\n",
    "\n",
    "pandas has been imported as pd, and the income DataFrame from the previous exercise is in your workspace.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Using the appropriate functions, calculate the mean of income per capita as mean and the standard deviation as std.\n",
    "Without using .quantile(), calculate and print the upper and lower bounds of an interval of one standard deviation around the mean in a list bounds:\n",
    "subtract std from mean as the first element\n",
    "add std to mean as the second element\n",
    "Using .quantile() and a list of two appropriate decimal values, calculate and print the first and the third quartile of 'Income per Capita' as quantiles. Do the values match?\n",
    "Calculate and print the IQR, iqr, using the simple subtraction expression you learned in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79331d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean\n",
    "mean = income['Income per Capita'].mean()\n",
    "\n",
    "# Calculate standard deviation\n",
    "std = income['Income per Capita'].std()\n",
    "\n",
    "# Calculate and print lower and upper bounds\n",
    "bounds = [mean - std, mean + std]\n",
    "print(bounds)\n",
    "\n",
    "# Calculate and print first and third quartiles\n",
    "quantiles = income['Income per Capita'].quantile([.25 , .75])\n",
    "print(quantiles)\n",
    "\n",
    "# Calculate and print IQR\n",
    "iqr = quantiles[.75] - quantiles[.25]\n",
    "print(iqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b9376c",
   "metadata": {},
   "source": [
    "Deciles of the global income distribution\n",
    "A decile is a special kind of quantile obtained by dividing the distribution of a particular dataset by ten. Deciles (as well as any other kind of quantile) can be created by supplying the following numpy function to .quantile(), where start is the beginning of the interval (inclusive), stop is the end of the interval (exclusive), and step is the spacing between any two adjacent values:\n",
    "\n",
    "np.arange(start, stop, step)\n",
    "As you saw in the video, a standard bar graph is a great way to visualize the distribution of data. You can create one by adding kind='bar' as an argument to .plot().\n",
    "\n",
    "Now it's your turn to apply this knowledge to plot a summary of the income distribution in deciles! pandas as pd, numpy as np, and matplotlib.pyplot as plt have been imported for you, and the income DataFrame from the previous exercise is available in your workspace.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Generate the percentages from 10% to 90% with increments of 10% using np.arange(), assign the result to quantiles, and print it.\n",
    "Using quantiles and .quantile(), calculate the deciles for the income per capita as deciles, and print the result.\n",
    "Plot and show the result as a bar chart with plt.tight_layout(). Title it 'Global Income per Capita - Deciles'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4911161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate range of deciles\n",
    "quantiles = np.arange(0.1, 0.91, 0.1)\n",
    "\n",
    "# Print them\n",
    "print(quantiles)\n",
    "\n",
    "# Calculate deciles for 'Income per Capita'\n",
    "deciles = income['Income per Capita'].quantile(quantiles)\n",
    "\n",
    "# Print them\n",
    "print(deciles)\n",
    "\n",
    "# Plot deciles as a bar chart\n",
    "deciles.plot(kind='bar', title='Global Income per Capita - Deciles')\n",
    "\n",
    "# Make sure to use the tight layout!\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d9ea3a",
   "metadata": {},
   "source": [
    "Visualizing international income distribution\n",
    "seaborn is a Python visualization library for statistical data visualization based on matplotlib.\n",
    "\n",
    "By default, the distplot() function in the seaborn package creates a histogram, where data is grouped into ranges and and plotted as bars, and fits a kernel density estimation (KDE), or smoothed histogram. You can also use distplot() to create another kind of graph called a rugplot, which adds markers at the bottom of the chart to indicate the density of observations along the x axis.\n",
    "\n",
    "seaborn.distplot(a, bins=None, hist=True, kde=True, rug=False, ...)\n",
    "In previous exercises, you created a quantile plot which provided a fairly granular sense of the level of income per capita at different points of the distribution. Here, you will use distplot() to get the full picture!\n",
    "\n",
    "pandas has been imported as pd, and the income DataFrame from the previous exercise is available in your workspace.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Import seaborn as sns and matplotlib.pyplot as plt.\n",
    "Print the summary statistics provided by .describe().\n",
    "Plot and show a basic histogram of the 'Income per Capita' column with .distplot().\n",
    "Create and show a rugplot of the same data by setting the additional arguments bins equal to 50, kde to False, and rug to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f081ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import seaborn and matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Print the summary statistics for income\n",
    "print(income.describe())\n",
    "income.sort_values(by = ['Income per Capita'])\n",
    "\n",
    "# Plot a basic histogram of income per capita\n",
    "income['Income per Capita'].plot()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Plot a rugplot\n",
    "sns.distplot(income['Income per Capita'])\n",
    "sns.distplot(income['Income per Capita'], bins = 50, kde = False, rug = True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3504704",
   "metadata": {},
   "source": [
    "Growth rates in Brazil, China, and the US\n",
    "It's time to extend your analysis beyond the levels of international per capita income to the growth rates. The 'income_growth.csv' file contains the growth rates of per capita income over the last 40 years for Brazil, China, and the US.\n",
    "\n",
    "You will plot the distribution of the historical growth rates for each country on the same chart using a KDE plot to faciliate visual comparison of the ranges of growth that these markets have experienced over this time period.\n",
    "\n",
    "From this point in the course onwards, you should always inspect any DataFrame with .info() in your console even if this isn't explicitly in the instructions. pandas as pd, seaborn as sns, and matplotlib.pyplot as plt have been imported.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Load the file 'income_growth.csv' into the variable growth. Parse the 'DATE' column into dtype datetime64 and set it as the index.\n",
    "Inspect the summary statistics for these three growth rates using the appropriate function.\n",
    "Iterate over the growth.columns attribute in a for loop to access their labels. Most of the code has been outlined for you.\n",
    "In each iteration of distplot(), pass in the iteration variable column to select the respective column, set the keyword hist to False, and set label to column.\n",
    "Show the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file into growth\n",
    "growth = pd.read_csv('income_growth.csv', parse_dates=['DATE']).set_index(['DATE'])\n",
    "\n",
    "# Inspect the summary statistics for the growth rates\n",
    "growth.describe()\n",
    "\n",
    "# Iterate over the three columns\n",
    "for column in growth.columns:\n",
    "    sns.distplot(growth[column], hist=False, label=column)\n",
    "    \n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d602ae",
   "metadata": {},
   "source": [
    "Highlighting values in the distribution\n",
    "Sometimes it is necessary to manipulate your data in order to create a better visualization. Two methods that can take care of missing values are .dropna() and .fillna(). You can also remove outliers by filtering entries that are over or under a certain percentile by applying a condition using .quantile() to a particular column.\n",
    "\n",
    "You also saw in the video how to emphasize a particular value in a plot by adding a vertical line at position x across the axes:\n",
    "\n",
    "Axes.axvline(x=0, color=None, ...)\n",
    "In this exercise, you will take a final look at global income distribution, and then remove outliers above the 95th percentile, plot the distribution, and highlight both the mean and median values. pandas as pd, seaborn as sns, and matplotlib.pyplot as plt have been imported, and the income DataFrame from previous exercises is available in your workspace.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Assign the column 'Income per Capita' to inc_per_capita.\n",
    "Filter to keep only the rows in inc_per_capita that are lower than the 95th percentile. Reassign to the same variable.\n",
    "Plot a default histogram for the filtered version of inc_per_capita and assign it to ax.\n",
    "Use ax.axvline() with color='b' to highlight the mean of inc_per_capita in blue,\n",
    "Use ax.axvline() with color='g' to highlight the median in green. Show the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e26b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inc_per_capita\n",
    "inc_per_capita = income['Income per Capita']\n",
    "\n",
    "# Filter out incomes above the 95th percentile\n",
    "inc_per_capita = inc_per_capita[inc_per_capita < inc_per_capita.quantile(.95)]\n",
    "\n",
    "# Plot histogram and assign to ax\n",
    "ax = sns.distplot(inc_per_capita)\n",
    "\n",
    "# Highlight mean\n",
    "ax.axvline(inc_per_capita.mean(), color='b')\n",
    "\n",
    "# Highlight median\n",
    "ax.axvline(inc_per_capita.median(), color='g')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd3ab6e",
   "metadata": {},
   "source": [
    "Companies by sector on all exchanges\n",
    "A categorical variable is a variable that is one of a limited number of values based on some qualitative property. A frequency distribution is a representation of the number of times that a categorical variable occurs.\n",
    "\n",
    "Think back to the stock exchange data from the earlier chapters. The .mean() function isn't very helpful for understanding the frequency of 'Sector' values such as 'Technology' and 'Finance', whereas .value_counts() and .nunique() are.\n",
    "\n",
    "In this exercise, you will compare the distribution of listings in the AMEX, NASDAQ, and NYSE per sector. pandas as pd and matplotlib.pyplot as plt have been imported, and the listings information from previous exercises has been loaded into a dictionary listings for which the keys are 'amex', 'nasdaq', and 'nyse'.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Create a list exchanges containing the exact strings of the names of the exchanges in the order listed above.\n",
    "Use a for loop to iterate over exchanges with an iterator variable exchange that contains the name of each exchange. In each iteration:\n",
    "Apply .value_counts() to 'Sector' and assign the result to sectors.\n",
    "Sort sectors in descending order and plot them in a bar plot.\n",
    "Show the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e25b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list exchanges\n",
    "exchanges = ['amex', 'nasdaq', 'nyse']\n",
    "\n",
    "# Iterate over exchanges then plot and show result\n",
    "for exchange in exchanges:\n",
    "    sectors = listings[exchange].Sector.value_counts()\n",
    "    # Sort in descending order and plot\n",
    "    sectors.sort_values(ascending=False).plot(kind='bar')\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184eaa93",
   "metadata": {},
   "source": [
    "Technology IPOs by year on all exchanges\n",
    "Each company in the listings dictionary has an IPO year between 1972 and 2017. Therefore, in this context, it is appropriate to consider the 'IPO Year' column of each sheet as a categorical variable with a well-defined order even though it is of dtype float64.\n",
    "\n",
    "Here you will combine data from all three exchanges and plot the distribution of IPO years for companies in the Technology sector. pandas as pd and matplotlib.pyplot as plt have been imported, and the listings dictionary from the previous exercise is in your workspace.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Use a for loop with iterator variable exchange that contains the name of each exchange.\n",
    "In each iteration, append the DataFrame corresponding to the key exchange in listings to all_listings.\n",
    "After the loop completes, use pd.concat() to combine the three DataFrames in all_listings and assign the result to listing_data.\n",
    "Filter listing_data for 'Technology' companies and assign the result to tech_companies.\n",
    "Assign the 'IPO Year' column from tech_companies to ipo years.\n",
    "For this data, use .dropna() to remove missing values and .astype() to convert to int.\n",
    "Apply .value_counts() to ipo_years, sort the years in ascending order, and create a bar plot titled 'Tech IPOs by Year'.\n",
    "Rotate xticks by 45 degrees and show the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists\n",
    "exchanges = ['amex', 'nasdaq', 'nyse']\n",
    "all_listings = []\n",
    "\n",
    "# Use for loop to create listing_data\n",
    "for exchange in exchanges:\n",
    "    all_listings.append(listings[exchange])\n",
    "    \n",
    "# Combine DataFrames\n",
    "listing_data = pd.concat(all_listings)\n",
    "\n",
    "# Select tech companies\n",
    "tech_companies = listing_data[listing_data.Sector == 'Technology']\n",
    "\n",
    "# Create ipo_years\n",
    "ipo_years = tech_companies['IPO Year']\n",
    "\n",
    "# Drop missing values and convert to int\n",
    "ipo_years = ipo_years.dropna().astype(int)\n",
    "\n",
    "# Count values, sort ascending by year, and create a bar plot\n",
    "ipo_years.value_counts(ascending=True).plot(kind='bar', title='Tech IPOs by Year')\n",
    "\n",
    "# Rotate xticks and show result\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb906a51",
   "metadata": {},
   "source": [
    "Median market capitalization by sector\n",
    "Aggregate data is data combined from several measurements. As you learned in the video, the .groupby() function is helpful in aggregating your data by a specific category.\n",
    "\n",
    "You have seen previously that the market capitalization data has large outliers. To get a more robust summary of the market value of companies in each sector, you will calculate the median market capitalization by sector. pandas as pd and matplotlib.pyplot as plt have been imported, and the NYSE stock exchange listings are available in your workspace as the DataFrame nyse.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Inspect nyse using .info().\n",
    "With broadcasting and .div(), create a new column market_cap_m that contains the market capitalization in million USD.\n",
    "Omit the column 'Market Capitalization' with .drop().\n",
    "Apply the .groupby() method to nyse, using 'Sector' as the column to group your data by.\n",
    "Calculate the median of the market_cap_m column as median_mcap_by_sector.\n",
    "Plot the result as a horizontal bar chart with the title 'NYSE - Median Market Capitalization'. Use plt.xlabel() with 'USD mn' to add a label.\n",
    "Show the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0594ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect NYSE data\n",
    "nyse.info()\n",
    "\n",
    "# Create market_cap_m\n",
    "nyse['market_cap_m'] = nyse['Market Capitalization'].div(1e6)\n",
    "\n",
    "# Drop market cap column\n",
    "nyse = nyse.drop('Market Capitalization', axis=1)\n",
    "\n",
    "# Group nyse by sector\n",
    "mcap_by_sector = nyse.groupby('Sector')\n",
    "\n",
    "# Calculate median\n",
    "median_mcap_by_sector = mcap_by_sector.market_cap_m.median()\n",
    "\n",
    "# Plot and show as horizontal bar chart\n",
    "median_mcap_by_sector.plot(kind='barh', title='NYSE - Median Market Capitalization')\n",
    "\n",
    "# Add the label\n",
    "plt.xlabel('USD mn')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b8fe3",
   "metadata": {},
   "source": [
    "Median market capitalization by IPO year\n",
    "In the last lesson of the previous chapter, you created a timeline for the number of IPOs per year for technology companies.\n",
    "\n",
    "Let's now analyze how market capitalization has evolved for different IPO years. You can combine data from all three exchanges to get a more comprehensive view.\n",
    "\n",
    "pandas as pd and matplotlib.pyplot as plt have been imported, and the listings DataFrame from previous exercises which now includes an added reference column 'exchange' that contains the exchange for each listed company, is available in your workspace.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Inspect and display listings using .info() and .head().\n",
    "Using broadcasting, create a new column market_cap_m for listings that contains the market cap in millions of USD.\n",
    "Select all companies with an 'IPO Year' after 1985.\n",
    "Drop all missing values in the 'IPO Year' column, and convert the remaining values to dtype integer.\n",
    "Group listings by 'IPO Year', select the market_cap_m column and calculate the median, sort with .sort_index(), and assign the result to ipo_by_year.\n",
    "Plot and show the results as a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c676b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect listings\n",
    "listings.info()\n",
    "\n",
    "# Show listings head\n",
    "print(listings.head())\n",
    "\n",
    "# Create market_cap_m\n",
    "listings['market_cap_m'] = listings['Market Capitalization'].div(1e6)\n",
    "\n",
    "# Select companies with IPO after 1985\n",
    "listings = listings[listings['IPO Year'] > 1985]\n",
    "\n",
    "# Drop missing values and convert to integers\n",
    "listings['IPO Year'] = listings['IPO Year'].dropna().astype(int)\n",
    "\n",
    "# Calculate the median market cap by IPO Year and sort the index\n",
    "ipo_by_year = listings.groupby('IPO Year').market_cap_m.median().sort_index()\n",
    "\n",
    "# Plot results as a bar chart\n",
    "ipo_by_year.plot(kind='bar')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b3db90",
   "metadata": {},
   "source": [
    "All summary statistics by sector\n",
    "You can apply the various summary statistics that you have learned about in the last chapter to a groupby object to obtain the result on a per-category basis. This includes the .describe() function, which provides several insights all at once!\n",
    "\n",
    "Here, you will practice this with the NASDAQ listings. pandas has been imported as pd, and the NASDAQ stock exchange listings data is available in your workspace in the nasdaq DataFrame.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Inspect the nasdaq data using .info().\n",
    "Create a new column market_cap_m that contains the market cap in millions of USD. On the next line, drop the column 'Market Capitalization'.\n",
    "Group your nasdaq data by 'Sector' and assign to nasdaq_by_sector.\n",
    "Call the method .describe() on nasdaq_by_sector, assign to summary, and print the result.\n",
    "This works, but result is in long format and uses a pd.MultiIndex() that you saw earlier. Convert summary to wide format by calling .unstack()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55103e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect NASDAQ data\n",
    "nasdaq.info()\n",
    "\n",
    "# Create market_cap_m\n",
    "nasdaq['market_cap_m'] = nasdaq['Market Capitalization'].div(1e6)\n",
    "\n",
    "# Drop the Market Capitalization column\n",
    "nasdaq.drop('Market Capitalization', axis=1, inplace=True)\n",
    "\n",
    "# Group nasdaq by Sector\n",
    "nasdaq_by_sector = nasdaq.groupby('Sector')\n",
    "\n",
    "# Create summary statistics by sector\n",
    "summary = nasdaq_by_sector.describe()\n",
    "\n",
    "# Print the summary\n",
    "print(summary)\n",
    "\n",
    "# Unstack \n",
    "summary = summary.unstack()\n",
    "\n",
    "# Print the summary again\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3d16d6",
   "metadata": {},
   "source": [
    "Company value by exchange and sector\n",
    "You can generate more fine-grained summaries of your data by providing a list of columns inside .groupby() and/or applying a statistical method such as .mean() directly to one or more numerical columns.\n",
    "\n",
    "Here, you will calculate the median market capitalization for each sector, differentiated by the exchange that the companies are listed on. You will also use .unstack() to pivot the exchange labels from the rows into the columns. It's a good idea to inspect listings in your console before starting the exercise!\n",
    "\n",
    "pandas as pd and matplotlib.pyplot as plt have been imported, and the listings DataFrame, with reference column 'Exchange' and a new column market_cap_m that contains the market cap in millions of USD, is available in your workspace.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Group your data by both 'Sector' and 'Exchange', assigning the result to by_sector_exchange.\n",
    "Calculate the median market capitalization for by_sector_exchange and assign to mcap_by_sector_exchange.\n",
    "Display the first 5 rows of the result with .head().\n",
    "Call .unstack() on mcap_by_sector_exchange to move the Exchange labels to the columns, and assign to mcap_unstacked.\n",
    "Plot the result as a bar chart with the title 'Median Market Capitalization by Exchange' and xlabel set to 'USD mn',\n",
    "Show the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86165e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group listings by Sector and Exchange\n",
    "by_sector_exchange = listings.groupby(['Sector', 'Exchange'])\n",
    "\n",
    "# Calculate the median market cap\n",
    "mcap_by_sector_exchange = by_sector_exchange.market_cap_m.median()\n",
    "\n",
    "# Display the head of the result\n",
    "print(mcap_by_sector_exchange.head())\n",
    "\n",
    "# Unstack mcap_by_sector_exchange\n",
    "mcap_unstacked = mcap_by_sector_exchange.unstack()\n",
    "\n",
    "# Plot as a bar chart\n",
    "mcap_unstacked.plot(kind='bar', title='Median Market Capitalization by Exchange')\n",
    "\n",
    "# Set the x label\n",
    "plt.xlabel('USD mn')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18cf9b2",
   "metadata": {},
   "source": [
    "Calculate several metrics by sector and exchange\n",
    "The .agg() function allows you to aggregate your data in even more ways by accepting two kinds of arguments. Providing a list of names of statistical methods calculates more than one summary statistic at once, and providing a dictionary where keys are column names and values are statistical methods applies a particular summary statistic to a designated column.\n",
    "\n",
    "In this exercise, you will calculate the mean, median, and standard deviation of market capitalizations in millions of USD. pandas as pd and matplotlib.pyplot as plt have been imported, and the listings DataFrame, with reference column 'Exchange' is available in your workspace.\n",
    "\n",
    "Instructions\n",
    "\n",
    "With broadcasting and .div(), create a new column 'market_cap_m' that contains the market capitalization data in millions of USD.\n",
    "Group your data by both 'Sector' and 'Exchange', assigning the result to by_sector_exchange.\n",
    "Assign the market_cap_m column of by_sector_exchange to a variable bse_mcm.\n",
    "Use .agg() and a dictionary argument to calculate the mean, median, and standard deviation for market_cap_m storing the results in 'Average', 'Median', and 'Standard Deviation', respectively, and assign to summary.\n",
    "Print the result to your console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a43091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create market_cap_m\n",
    "listings['market_cap_m'] = listings['Market Capitalization'].div(1e6)\n",
    "\n",
    "# Group listing by both Sector and Exchange\n",
    "by_sector_exchange = listings.groupby(['Sector', 'Exchange'])\n",
    "\n",
    "# Subset market_cap_m of by_sector_exchange\n",
    "bse_mcm = by_sector_exchange['market_cap_m']\n",
    "\n",
    "# Calculate mean, median, and std in summary\n",
    "summary = bse_mcm.agg({'Average': 'mean', 'Median': 'median', 'Standard Deviation': 'std'})\n",
    "\n",
    "# Print the summary\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c456fae",
   "metadata": {},
   "source": [
    "Plot IPO timeline for all exchanges using countplot()\n",
    "To create a basic visualization of the number of observations per category in a dataset, the seaborn countplot() function is usually the way to go:\n",
    "\n",
    "seaborn.countplot(x=None, hue=None, data=None, ...)\n",
    "The x parameter contains the names of the variables in the data argument, which is the DataFrame to be plotted. hue identifies an additional categorical variable with color. These are three optional parameters out of many accepted by the function; for a full list, check out the seaborn documentation.\n",
    "\n",
    "Let's use this tool to compare the timeline of IPO activity across the three exchanges. pandas as pd, matplotlib.pyplot as plt, and seaborn as sns have been imported, and the listings DataFrame with reference column 'Exchange' is available in your workspace.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Filter listings to only include IPO years after the year 2000.\n",
    "Convert the data in the column 'IPO Year' to integers.\n",
    "Plot a sns.countplot() of listings using 'IPO Year' as the x variable and 'Exchange' for hue.\n",
    "Rotate the xticks() by 45 degrees and show the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6f1a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select IPOs after 2000\n",
    "listings = listings[listings['IPO Year'] > 2000]\n",
    "\n",
    "# Convert IPO Year to integer\n",
    "listings['IPO Year'] = listings['IPO Year'].astype(int)\n",
    "\n",
    "# Create a countplot\n",
    "sns.countplot(x='IPO Year', hue='Exchange', data=listings)\n",
    "\n",
    "# Rotate xticks and show result\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6045fa84",
   "metadata": {},
   "source": [
    "Global median per capita income over time\n",
    "The seaborn barplot() function shows point estimates and confidence intervals as rectangular bars; the default function displays the mean, but it can also represent another summary statistic if you pass a particular numpy function to its estimator parameter:\n",
    "\n",
    "seaborn.barplot(x=None, y=None, data=None, estimator=<function mean>, ...)\n",
    "In this exercise, you will use an imported World Bank dataset containing global income per capita data for 189 countries since the year 2000. To practice displaying summary statistics per category, you will plot and compare the median global income per capita since 2000 to the mean.\n",
    "\n",
    "pandas as pd, numpy as np, matplotlib.pyplot as plt, and seaborn as sns have been imported. The global income data is available in your workspace in income_trend.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Inspect income_trend using .info().\n",
    "Create a sns.barplot() using the column 'Year' for x and 'Income per Capita' for y, and show the result after rotating the xticks by 45 degrees.\n",
    "Use plt.close() after the initial plt.show() to be able to show a second plot.\n",
    "Create a second sns.barplot() with the same x and y settings, using estimator=np.median to calculate the median, and show the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f07a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the data\n",
    "income_trend.info()\n",
    "\n",
    "# Create barplot\n",
    "sns.barplot(x='Year', y='Income per Capita', data=income_trend)\n",
    "\n",
    "# Rotate xticks\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Close the plot\n",
    "plt.close()\n",
    "\n",
    "# Create second barplot\n",
    "sns.barplot(x='Year', y='Income per Capita', data=income_trend, estimator=np.median)\n",
    "\n",
    "# Rotate xticks\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec971b3c",
   "metadata": {},
   "source": [
    "Calculate several metrics by sector and IPO year\n",
    "The seaborn pointplot() function facilitates the comparison of summary statistics of a numerical variable for different levels of categorical variables:\n",
    "\n",
    "seaborn.pointplot(x=None, y=None, hue=None, data=None, ...)\n",
    "In the video, you saw a visualization for the market capitalization (the numerical variable) differentiated by whether the IPO (the categorical variable) occurred before (first level) or after (second level) the year 2000.\n",
    "\n",
    "In this exercise, you will compare the mean market capitalization for each year since 2000 for the NYSE and the NASDAQ, after excluding outliers beyond the 95th percentile. pandas as pd and matplotlib.pyplot as plt have been imported, and the listings DataFrame with reference column 'Exchange' is available in your workspace.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Import seaborn as sns.\n",
    "Filter listings to have companies with IPOs after 2000 from all exchanges except the 'amex'.\n",
    "Convert the data in column 'IPO Year' to integers.\n",
    "Create the column market_cap_m to express market cap in USD million.\n",
    "Filter market_cap_m to exclude values above the 95th percentile.\n",
    "Create a pointplot of listings using the column 'IPO Year' for x, 'market_cap_m' for y, and 'Exchange' for hue. Show the result after rotating the xticks by 45 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb02e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the seaborn library as sns\n",
    "import seaborn as sns\n",
    "\n",
    "# Exclude IPOs before 2000 and from the 'amex'\n",
    "listings = listings[(listings['IPO Year'] > 2000) & (listings.Exchange != 'amex')]\n",
    "\n",
    "# Convert IPO Year to integer\n",
    "listings['IPO Year'] = listings['IPO Year'].astype(int)\n",
    "\n",
    "# Create market_cap_m\n",
    "listings['market_cap_m'] = listings['Market Capitalization'].div(1e6)\n",
    "\n",
    "# Exclude outliers\n",
    "listings = listings[listings.market_cap_m < listings.market_cap_m.quantile(.95)]\n",
    "\n",
    "# Create the pointplot\n",
    "sns.pointplot(x='IPO Year', y='market_cap_m', hue='Exchange', data=listings)\n",
    "\n",
    "# Rotate xticks\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f45161",
   "metadata": {},
   "source": [
    "Inflation trends in China, India, and the US\n",
    "Finally, the seaborn package includes functions that allow you to visualize the distribution of levels of categorical variables.\n",
    "\n",
    "In the next two exercises, you will examine the historical inflation data in China, India, and the US over the past 50+ years in data from FRED. Before jumping into using the functions you have just learned, you should first familiarize yourself with the raw data. pandas as pd, matplotlib.pyplot as plt, and seaborn as sns have been imported for you. The FRED inflation data is in your workspace as inflation.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Inspect inflation using .info().\n",
    "Group inflation by 'Country' and assign to inflation_by_country.\n",
    "In a for loop, iterate over country, data pairs returned by inflation_by_country. In each iteration, use .plot() on data with title set to country to show the historical time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6510f60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the inflation data\n",
    "inflation.info()\n",
    "\n",
    "# Create inflation_by_country\n",
    "inflation_by_country = inflation.groupby('Country')\n",
    "\n",
    "# Iterate over inflation_by_country and plot the inflation time series per country\n",
    "for country, data in inflation_by_country:\n",
    "    # Plot the data\n",
    "    data.plot(title=country)\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d44da52",
   "metadata": {},
   "source": [
    "Distribution of inflation rates in China, India, and the US\n",
    "As you saw in the video, the boxplot() function displays key quantiles of a distribution with respect to categories, where y represents a quantitative variable, and x a categorical variable. In statistics, this kind of distribution is known as a box-and-whisker plot.\n",
    "\n",
    "A complement to a box plot is a swarmplot(), which draws a categorical scatterplot that displays all categorical observations without overlapping; it takes similar arguments to boxplot():\n",
    "\n",
    "seaborn.boxplot(x=None, y=None, data=None, ...)\n",
    "seaborn.swarmplot(x=None, y=None, data=None, ...)\n",
    "In this final exercise, you will compare the historical distributions of inflation rates by country - specifically China, India, and the US - instead of by time series trends. pandas as pd, matplotlib.pyplot as plt, and seaborn as sns have been imported for you. The FRED inflation data is in your workspace as inflation.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Create and show a boxplot of the inflation data with 'Country' for x and 'Inflation' for y.\n",
    "Create and show sns.swarmplot() with the same arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8314f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplot\n",
    "sns.boxplot(x='Country', y='Inflation', data=inflation)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Close the plot\n",
    "plt.close()\n",
    "\n",
    "# Create swarmplot\n",
    "sns.swarmplot(x='Country', y='Inflation', data=inflation)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
